"""
Question Cleaning Agent

Purpose: Refines the question generated by the question gen model to align with
what the orchestrator wants to ask about the specific resume point.
"""

from typing import Dict
from app.services.local_llm_service import local_llm_service


async def question_cleaning_agent(
    generated_question: str,
    resume_point: str,
    orchestrator_intent: str,
    domain: str
) -> Dict:
    """
    Cleans and refines the generated question to match orchestrator's intent
    
    Args:
        generated_question: Question from the question gen model
        resume_point: The specific resume point being discussed
        orchestrator_intent: What the orchestrator wants to ask about
        domain: The technical domain
    
    Returns:
        {
            "cleaned_question": "Refined question text",
            "success": True/False
        }
    """
    
    prompt = f"""Blend this technical question with the candidate's resume context to create one natural interview question.

Technical Question: {generated_question}

Resume Context: {resume_point[:300]}

Domain: {domain}

Create ONE question that:
- Starts by acknowledging their resume experience
- Then asks the technical question naturally
- Sounds like a real interviewer

"""
    
    try:
        messages = [
                {
                    "role": "system",
                    "content": "You are an expert at creating natural interview questions. Return ONLY the question, no explanations."
                },
                {
                    "role": "user",
                    "content": prompt
                }
        ]
        
        cleaned_question = await local_llm_service.generate_async(messages, max_new_tokens=1500, temperature=0.7)
        
        # Handle None response
        if cleaned_question is None or not cleaned_question.strip():
            print("Question cleaning returned None or empty, using original question")
            return {
                "cleaned_question": generated_question,
                "success": False,
                "error": "LLM returned empty response"
            }
        
        # Clean up the response aggressively
        # Remove quotes
        cleaned_question = cleaned_question.strip('"\'')
        
        # Take only the first sentence or up to first question mark
        if '?' in cleaned_question:
            # Include everything up to and including the first question mark
            cleaned_question = cleaned_question.split('?')[0] + '?'
        else:
            # If no question mark, take first line
            cleaned_question = cleaned_question.split('\n')[0]
        
        # Remove any meta-commentary
        meta_phrases = [
            "Here's",
            "Here is",
            "The question",
            "This question",
            "Example:",
            "Format:",
        ]
        for phrase in meta_phrases:
            if cleaned_question.startswith(phrase):
                # Skip to after the first colon if present
                if ':' in cleaned_question:
                    cleaned_question = cleaned_question.split(':', 1)[1].strip()
        
        cleaned_question = cleaned_question.strip()
        
        return {
            "cleaned_question": cleaned_question,
            "success": True
        }
        
    except Exception as e:
        print(f"Question cleaning failed: {str(e)}")
        # Fallback: Return original question
        return {
            "cleaned_question": generated_question,
            "success": False,
            "error": str(e)
        }
