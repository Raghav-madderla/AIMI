{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from huggingface_hub import InferenceClient\n",
        "import time\n",
        "import re\n",
        "import ast\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "HF_ENDPOINT_URL = \"\"\n",
        "HF_TOKEN = \"\"\n",
        "GEMINI_API_KEY = \"\"\n",
        "\n",
        "# Clients\n",
        "hf_client = InferenceClient(base_url=HF_ENDPOINT_URL, token=HF_TOKEN)\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# --- 2. HELPER FUNCTIONS ---\n",
        "def calculate_perplexity(response_details):\n",
        "    \"\"\"\n",
        "    Robustly calculates PPL. Returns 0.0 if logprobs are unavailable.\n",
        "    \"\"\"\n",
        "    # SAFETY CHECK: If the endpoint didn't return details, skip PPL\n",
        "    if response_details is None:\n",
        "        return 0.0\n",
        "\n",
        "    tokens = response_details.tokens\n",
        "    if not tokens: return 0.0\n",
        "\n",
        "    # Collect logprobs\n",
        "    log_probs = [t.logprob for t in tokens if t.logprob is not None]\n",
        "\n",
        "    if not log_probs: return 0.0\n",
        "    return math.exp(-np.mean(log_probs))\n",
        "\n",
        "def clean_and_parse_json(text):\n",
        "    try:\n",
        "        match = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
        "        if match:\n",
        "            return json.loads(match.group(0))\n",
        "        return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def gemini_question_judge(domain, difficulty, generated_question):\n",
        "    model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
        "\n",
        "    rubric = \"\"\"\n",
        "    1. Domain Validity: Is this definitely a question about the specific Domain?\n",
        "    2. Difficulty Alignment: Does the complexity match the requested Difficulty?\n",
        "    3. Phrasing Quality: Is the question clear, professional, and interview-ready?\n",
        "    4. Solvability: Is it a valid question with a reasonable answer?\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"You are an Expert Interviewer. Evaluate this AI-generated interview question.\n",
        "\n",
        "    ### Input Parameters:\n",
        "    - Target Domain: {domain}\n",
        "    - Target Difficulty: {difficulty}\n",
        "\n",
        "    ### AI Generated Question:\n",
        "    {generated_question}\n",
        "\n",
        "    ### Task:\n",
        "    Evaluate the question based on the Rubric.\n",
        "    Return ONLY JSON:\n",
        "    {{\n",
        "        \"domain_score\": int (1-5), \"domain_reason\": \"string\",\n",
        "        \"difficulty_score\": int (1-5), \"difficulty_reason\": \"string\",\n",
        "        \"phrasing_score\": int (1-5), \"phrasing_reason\": \"string\",\n",
        "        \"overall_score\": float\n",
        "    }}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        # Robust cleanup for Gemini markdown output\n",
        "        clean_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "        return json.loads(clean_text)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# --- 3. BENCHMARK PROMPTS ---\n",
        "benchmark_prompts = [\n",
        "    {\"domain\": \"Python\", \"difficulty\": \"Basic\"},\n",
        "    {\"domain\": \"Python\", \"difficulty\": \"Medium\"},\n",
        "    {\"domain\": \"Python\", \"difficulty\": \"Advanced\"},\n",
        "    {\"domain\": \"SQL\", \"difficulty\": \"Medium\"},\n",
        "    {\"domain\": \"SQL\", \"difficulty\": \"Advanced\"},\n",
        "    {\"domain\": \"Machine Learning\", \"difficulty\": \"Medium\"},\n",
        "    {\"domain\": \"Deep Learning\", \"difficulty\": \"Advanced\"},\n",
        "    {\"domain\": \"System Design\", \"difficulty\": \"Advanced\"},\n",
        "]\n",
        "\n",
        "# --- 4. EXECUTION ---\n",
        "ppl_scores = []\n",
        "gemini_scores = []\n",
        "\n",
        "print(f\"Starting Question Generation Benchmark...\\n\")\n",
        "\n",
        "for i, item in enumerate(benchmark_prompts):\n",
        "    print(f\"Test {i+1}: {item['domain']} ({item['difficulty']})\")\n",
        "\n",
        "    # A. Format Prompt (Alpaca Style)\n",
        "    instruction = \"You are an expert interview question generator. Generate an interview question based on the parameters provided in the input.\"\n",
        "    input_params = f\"Domain: {item['domain']}\\nDifficulty: {item['difficulty']}\"\n",
        "\n",
        "    alpaca_prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input_params}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # B. Generate Question\n",
        "        response = hf_client.text_generation(\n",
        "            prompt=alpaca_prompt,\n",
        "            max_new_tokens=256,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            details=True, # We still ask for details\n",
        "            return_full_text=False\n",
        "        )\n",
        "\n",
        "        gen_text = response.generated_text.strip()\n",
        "        print(f\"   Generated: \\\"{gen_text[:80]}...\\\"\")\n",
        "\n",
        "        # C. Calculate Metrics (Robust Call)\n",
        "        ppl = calculate_perplexity(response.details)\n",
        "        if ppl > 0:\n",
        "            ppl_scores.append(ppl)\n",
        "            print(f\"   PPL: {ppl:.4f}\")\n",
        "        else:\n",
        "            #print(f\"   PPL Unavailable (Endpoint didn't return logprobs)\")\n",
        "            print('------')\n",
        "\n",
        "        # D. Gemini Judge\n",
        "        gemini_json = gemini_question_judge(item['domain'], item['difficulty'], gen_text)\n",
        "\n",
        "        if gemini_json:\n",
        "            g_score = gemini_json.get('overall_score', 0)\n",
        "            gemini_scores.append(g_score)\n",
        "\n",
        "            print(\"   Gemini Evaluation:\")\n",
        "            print(f\"      • Domain Match: {gemini_json.get('domain_score')}/5 - {gemini_json.get('domain_reason')}\")\n",
        "            print(f\"      • Diff. Match:  {gemini_json.get('difficulty_score')}/5 - {gemini_json.get('difficulty_reason')}\")\n",
        "            print(f\"      • Phrasing:     {gemini_json.get('phrasing_score')}/5\")\n",
        "            print(f\"      • Overall:      {g_score}/5\")\n",
        "        else:\n",
        "            print(\"      Gemini failed to evaluate\")\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "\n",
        "# --- 5. FINAL REPORT ---\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"Q-GEN BENCHMARK REPORT\")\n",
        "print(\"=\"*30)\n",
        "if ppl_scores:\n",
        "    print(f\"Avg Perplexity:        {np.mean(ppl_scores):.4f}\")\n",
        "else:\n",
        "    print(\"Avg Perplexity:        N/A (Not supported by this endpoint)\")\n",
        "\n",
        "if gemini_scores:\n",
        "    print(f\"Avg Gemini Quality:    {np.mean(gemini_scores):.2f} / 5.0\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fBLLZCGlzYRc",
        "outputId": "3709e8ed-137e-4875-b318-a2112cdba57d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Question Generation Benchmark...\n",
            "\n",
            "Test 1: Python (Basic)\n",
            "   Generated: \"What is a Pandas Series?<|end_of_text|>...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question directly targets the core concepts of the Python data science ecosystem, specifically the Pandas library. Pandas Series is a fundamental data structure within Pandas, making it highly relevant to the target domain.\n",
            "      • Diff. Match:  2/5 - The question asks for a definition of a basic data structure in Pandas. Answering this question requires knowledge of what a Series is, its properties, and its basic use cases, which aligns with a basic difficulty level. It doesn't require complex problem-solving or advanced syntax.\n",
            "      • Phrasing:     5/5\n",
            "      • Overall:      3.67/5\n",
            "--------------------------------------------------\n",
            "Test 2: Python (Medium)\n",
            "   Generated: \"Explain the purpose of the `__getattr__` method in Python. When would you choose...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question directly targets a specific, often misunderstood, feature within the Python language. Understanding special methods like `__getattr__` is a hallmark of medium to advanced Python proficiency.\n",
            "      • Diff. Match:  4/5 - While explaining the purpose is straightforward, discussing *when* to use it and its *limitations* requires a deeper understanding of Python's object model, introspection, and potential performance implications. This moves it beyond a simple definition into more practical application and critical analysis, aligning well with a medium difficulty level.\n",
            "      • Phrasing:     5/5\n",
            "      • Overall:      4.67/5\n",
            "--------------------------------------------------\n",
            "Test 3: Python (Advanced)\n",
            "   Generated: \"Given a list of integers and a target sum, write a Python function to find all u...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question directly targets core Python programming concepts and data structures (lists, functions). It requires the candidate to demonstrate knowledge of algorithms and data manipulation within the Python ecosystem.\n",
            "      • Diff. Match:  4/5 - While the problem itself is a classic 'two-sum' variation, the requirement for 'unique pairs' and the discussion of time/space complexity push it beyond an introductory level. An advanced candidate should be able to solve this efficiently (e.g., using sets or sorting) and articulate the trade-offs.\n",
            "      • Phrasing:     4/5\n",
            "      • Overall:      4.33/5\n",
            "--------------------------------------------------\n",
            "Test 4: SQL (Medium)\n",
            "   Generated: \"Given a table of employee performance scores (employee_id, score, date), how wou...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question directly tests knowledge of SQL, specifically with aggregation and window functions, which are core concepts within the SQL domain. The mention of a 'table of employee performance scores' and the requirement to calculate a percentile are highly relevant to SQL database operations.\n",
            "      • Diff. Match:  4/5 - This question is appropriately set at a medium difficulty level. It requires more than basic SELECT statements or simple aggregations. To correctly answer, a candidate needs to understand percentile calculation, which often involves window functions like `PERCENT_RANK()` or `NTILE()`, or a combination of `ORDER BY` and `LIMIT` with subqueries or CTEs. These concepts are beyond beginner but not advanced enough to be considered expert-level. It requires thoughtful application of SQL features.\n",
            "      • Phrasing:     4/5\n",
            "      • Overall:      4.33/5\n",
            "--------------------------------------------------\n",
            "Test 5: SQL (Advanced)\n",
            "   Generated: \"Given an 'Employees' table with columns 'EmployeeID', 'HireDate', and 'Terminati...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question is directly focused on SQL and requires a solid understanding of date functions, joins, aggregations, and conditional logic, which are core advanced SQL concepts. The scenario is practical and relevant to data analysis within a business context.\n",
            "      • Diff. Match:  4/5 - This question is challenging as it requires combining data from two tables, filtering based on date conditions (specifically within a 30-day window relative to the hire date), and then calculating a percentage. This involves multiple steps: identifying relevant interviews, comparing interview dates to hire dates, counting passes, counting total relevant employees, and then performing division with careful handling of potential division by zero. It's not a trivial SELECT or simple JOIN.\n",
            "      • Phrasing:     4/5\n",
            "      • Overall:      4.3/5\n",
            "--------------------------------------------------\n",
            "Test 6: Machine Learning (Medium)\n",
            "   Generated: \"What are the key differences between K-Means and DBSCAN clustering algorithms, a...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question directly addresses two fundamental and widely used clustering algorithms within the Machine Learning domain, requiring knowledge of their core concepts and practical applications.\n",
            "      • Diff. Match:  3/5 - The question asks for a comparison of two distinct algorithms and requires the candidate to justify their choices based on specific scenarios. This level of detail goes beyond a simple definition and necessitates a moderate understanding of their strengths, weaknesses, and underlying assumptions, aligning well with a medium difficulty.\n",
            "      • Phrasing:     5/5\n",
            "      • Overall:      4.33/5\n",
            "--------------------------------------------------\n",
            "Test 7: Deep Learning (Advanced)\n",
            "   Generated: \"Describe the fundamental differences between feedforward neural networks and rec...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question directly addresses core concepts within Deep Learning, specifically neural network architectures which are fundamental to the field.\n",
            "      • Diff. Match:  4/5 - The question requires a deep understanding of two major neural network types, their internal mechanisms (recurrent connections), their application (sequential data), common pitfalls (vanishing/exploding gradients), and knowledge of specific advanced architectures and their use cases. This goes beyond introductory knowledge.\n",
            "      • Phrasing:     5/5\n",
            "      • Overall:      4.67/5\n",
            "--------------------------------------------------\n",
            "Test 8: System Design (Advanced)\n",
            "   Generated: \"Design a RESTful API for a real-time location tracking system. Consider how you ...\"\n",
            "------\n",
            "   Gemini Evaluation:\n",
            "      • Domain Match: 5/5 - The question directly probes core concepts of system design, specifically focusing on API design for a distributed, real-time system. It touches upon critical aspects like scalability (concurrent requests), performance (caching), robustness (error handling), and data persistence choices (database trade-offs), all of which are central to advanced system design.\n",
            "      • Diff. Match:  4/5 - While the question is well-structured, the 'advanced' difficulty is slightly undermined by its broadness. It lists several important considerations (concurrent requests, caching, error handling, database trade-offs) but doesn't push for a deeply detailed solution in any single area. An advanced question might delve into specific challenges within one or two of these areas, or ask for a more complex architectural pattern.\n",
            "      • Phrasing:     4/5\n",
            "      • Overall:      4.33/5\n",
            "--------------------------------------------------\n",
            "\n",
            "==============================\n",
            "Q-GEN BENCHMARK REPORT\n",
            "==============================\n",
            "Avg Perplexity:        N/A (Not supported by this endpoint)\n",
            "Avg Gemini Quality:    4.33 / 5.0\n",
            "==============================\n"
          ]
        }
      ]
    }
  ]
}